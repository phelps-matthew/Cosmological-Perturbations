\documentclass[10pt,letterpaper]{article}
\usepackage{macroshw}

\title{\begin{spacing}{1.2}Quantum Mechanics III\\HW 1\end{spacing}}
\author{Matthew Phelps}
\date{Due: Jan. 27 }

\begin{document}
\maketitle

\benum
% #1 -----------------------------------------------------------------------------------------------------------------------------------------------------------------
  	 \item[1.1]
	 
	A collection of vectors $v_1,..., v_N$ is \emph{linearly independent} if the only way to make the zero
	vector as a linear combination of these vectors is to have all zero coefficients: $\lambda_1 v_1+...+
	\lambda_N v_N = 0\quad \Rightarrow \quad \lambda_1 = \lambda_2 = ... = \lambda_N = 0$. Otherwise
	the set of vectors is linearly dependent. Show that
	\benum
	% (a)
	\item
	A set of vectors is linearly dependent precisely when (at least) one of the vectors may be written as a linear
	combination of the others.
	% (b)
	\item
	If the set of vectors $v_1,...,v_N$ is orthonormal, it is linearly independent.
	\\ \\
	\eenum
	
	\benum
	\item 
	% (a)
	Take the set of vectors $\{v_n\}$ such that one vector $v_i$ is linearly dependent
	\[
		v_i = \sum_{j\ne i} c_j v_j,\ c_j \in \mathbb C
	\]
	Now form the zero vector as a linear combination of the vectors in the set (with $\lambda_i \in \mathbb C$)
	\[
		\lambda_1 v_1 + ... + \lambda_i v_i+ ... + \lambda_N v_N = \sum_i \lambda_j v_j  =  0
	\]
	which upon substitution of $v_i$ becomes
	\[
		\sum_{j\ne i} (c_j+\lambda_j)v_j = 0.
	\]
	For $v_j \ne 0$, we must then have $\lambda_j = -c_j$, hence
	\[
		 \forall\  \lambda_j \ \exists\   \{\lambda_k\} \subset \{\lambda_j\}: \sum_{j} \lambda_jv_j = 0, \{\lambda_k\} \ne 0
	\]
	(I may be abusing notation here; I wish to say that for all $\lambda_j$ there exists a subset $\{\lambda_k\}$ 
	such that $\sum_j \lambda_j = 0$ and $\{\lambda_k\}\ne 0$.) \\ 
	Since the coefficients are not uniquely zero in forming the zero vector, the set must be linearly dependent.  The 
	same argument may be repeated if more than one vector may be written as a linear combination of others.
	\\ \\
	\item 
	% (b)
	The decomposition of a vector $v$ lying within the space spanned by $\{v_N\}$ is given as 
	\[
		v = \sum_i \lambda_i v_i
	\]
	where
	\[
		\lambda_i = (v_i,v).
	\]
	Given the orthonormal set $\{v_N\}$ we may attempt to decompose any given vector $v_j$ within this set
	as 
	\[
		v_j = \sum_i (v_i,v_j)v_i = \sum_i \delta_{ij} v_i = v_j
	\]
	Hence no vector within the set $\{v_N\}$ can be decomposed as linear combination of other vectors.
	When we form the zero vector as a linear combination of vectors within the set for arbitrary 
	$\lambda_i \in \mathbb C$ 
	\[
		\sum_i \lambda_i v_i = 0
	\]
	we see that the only unique solution for $v_i\ne 0$ is $\forall i, \lambda_i = 0$. Hence the orthonormal set is linearly 
	independent. \\ \\
	\eenum 
	
	% 2 ----------------------------------------------------------------------------------------------------------------------------------------------------
	\item[1.3]
	
	Show that the set of vectors $\mathscr{P}_a = \{ u\in \mathscr H: Au = au\}$, which contains all 
	eigenvectors of $A$ corresponding to the eigenvalue $a$ and the zero vector, is a subspace of the
	quantum mechanical Hilbert space $\mathscr H$. 
	\\ \\
	$\forall c \in \mathbb C$
	\[
		A(cu) = c(Au) = a(cu)
	\] 
	and $\forall u_1,u_2 \in \mathscr P_a$
	\[
		A(u_1+u_2) = Au_1 + Au_2 = a(2u).
	\]
	Hence the space $\mathscr P_a$ is closed under addition and multiplication by a scalar. If we include the 
	zero vector, then $\mathscr{P}_a$ is a linear vector space and since its elements are necessarily vectors
	of the Hilbert spa
	ce, it is thus a subspace of $\mathscr H$. \\ \\ 
% 3 ------------------------------------------------------------------------------------------------------------------------------------------------------
	\item[1.4]
	Suppose that the operator $A$ is invertible. 
	
	\benum
	% (a)
	\item 
	Show that the inverse is unique.
	% (b)
	\item
	Show that if either $AX=1$ or $XA = 1$, then $X=A^{-1}$. 
	\\
	\eenum
	
	\benum
	\item
	% (a)
	Assume two inverse operators $\bar A^{-1}$ and $A^{-1}$ such that
	\[
		A\bar A^{-1} = \bar A^{-1} A = 1;\qquad AA^{-1} = A^{-1}A = 1
	\]
	then
	\[
		 \bar A^{-1} A  = A^{-1}A  \ \Rightarrow\   (\bar A^{-1}- A^{-1})A = 0 \ \Rightarrow\   \bar A^{-1} =  A^{-1} .
	\]
	Hence the inverse operator in unique. \\
	
	\item
	% (b)
	For $AX = 1$ we have, given the invertibility of $A$,
	\[
		AX = 1 = AA^{-1}\ \Rightarrow\ AX = AA^{-1}\ \Rightarrow\ A(X-A^{-1}) = 0
		\ \Rightarrow\ X = A^{-1}.
	\]
	Similarly for $XA = 1$
	\[
		XA = 1 = A^{-1}A \ \Rightarrow\ (X-A^{-1})A = 0\ \Rightarrow\ X = A^{-1}.
	\] \\
	\eenum
% 4 ------------------------------------------------------------------------------------------------------------------------------------------------------
	\item[1.5]
	a
	\benum
	% (a)
	\item
	Show by induction that if $[A,B] = 0$, then $[A^n,B] = 0$, $n= 0,1,2,...$. 
	% (b)
	\item
	Define a function $f$ via its power series, $f(z) = \sum_k b_kz^k$, and the corresponding function of the 
	operator $A$ (at least formally) using the same power series, $f(A) = \sum_k b_kA^k$. Show that if $[A,B]=0$,
	then also $[f(A),B] = 0$ and $[f(A),g(B)] = 0$ for any functions $f$ and $g$. Thus, arbitrary functions of two
	commuting operators also commute. 
	\eenum 
	\benum
	% (a)
	\item
	Basis:
	\[
		[A^0,B] = [\mathds 1,B] = 0.
	\]
	Induction:
	\\ \\
	Assume $[A^n,B]=0$, then
	\[
		[A^{n+1},B] = [A,B]A^n + A[A^n,B] = 0.
	\]
	
	% (b)
	\item
	\[
		[f(A),B] = [\sum b_k A^k, B] = \sum b_k[A^k,B] = 0
	\]
	where the proof from (a) was used. 
	\\ \\
	Define $g(B) = \sum_l c_l B^l$, then
	\ba
		[f(A),g(B)] &= \sum_{l} c_l [f(A), B^l] \\
		&= \sum_l c_l \plr{
		[f(A),B]B^{l-1}+B[f(A),B]B^{l-2} + B^2[f(A),B]B^{l-3} + ... + B^{l-1}[f(A),B]} \\
		& = 0
	\ea
	due to $[f(A),B]=0$. Thus
	\[
		[f(A),g(B)] = 0.
	\]
	\eenum
	
% 5 ------------------------------------------------------------------------------------------------------------------------------------------------------
	\item[1.8]
	Show that the operators $xp$ and $px$ are not hermitian, but the ``symmetrized" product 
	$ \frac{1}{2}(xp+px)$ is.
	\\ \\
	\[
		xp-(xp)^{\dag} = xp-p^\dag x^\dag = xp-px = [x,p] = i\h
	\]
	\[
		px-(px)^\dag = px-xp = -i\h
	\]
	\[
		\frac{1}{2}\plr{ xp+px}- \frac{1}{2}\plr{ xp+px}^\dag = \frac{1}{2}\plr{ xp+px} - \frac{1}{2}\plr{ px+xp} = 0 
	\]
	\eenum
\end{document}